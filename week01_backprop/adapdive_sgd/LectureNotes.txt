Adaptive optimization methods
    0) Обучение с учителем можно рассматривать как воссоздание функции, ставящей в соответствие каждому элементу входных
    данных x некоторый элемент y (например, картинке лейбл). Эта функция, как правило, имеет настраиваемые параметры (веса).
    1) Для бинарной классификации используется логистическая регрессия:
        а) вероятность принадлежности классу считается по формуле сигмоиды
        б) функция потерь представляет собой минус сумму логарифмов этих вероятностей
        в) по функции потерь можно вычислить градиент (просто не помню, какой)
    2) Для мультиклассификации используется softmax-loss функция:
        а) вероятность принадлежности одному из классов считается как отношение экспоненты к сумме экспонент
        б) функция потерь представляет собой минус сумму логарифмов этих вероятностей
        в) в градиенте можно видеть следующую семантику: если элемент определен классификатором к некоторому классу и
        на самом деле ему принадлежит (или, наоборот, не определен к этому классу и ему не принадлежит), то градиент в этой
        точке маленький (почти нулевой), т.к. для элемента уже все определяется верно; если элемент определен классификатором к классу, но
        на самом деле ему не принадлежит, то тогда градиент в этой точке отрицательный (отталкиваем такой элемент);
        если элемент не определен к классу, но принадлежит ему, то градиент в этой точке положительный (притягиваем такой
        элемент)
    3) Методы борьбы с переобучением:
        а) L2-регуляризация (сумма квадратов весов, домноженная на коэффициент)
        б) добавление шумов в данные (можно искусственно сделать аугментацию данных, добавляя по-разному шумы в одно и то
        же изображение)
    4) Построение модели включает в себя:
        а) этапы: определение проблемы и выбор функции потерь, выбор классификатора, вычисление потерь, получение результата
        б) переходы между ними:
            б.1) approximation error (1->2) - чем больше вероятность выбрать из множества классификаторов наиболее оптимальный,
            тем меньше данная ошибка
            б.2) estimation error (2->3) - чем больше заточенность под учебные данные и переобучения, тем выше эта ошибка
            б.3) optimization error (3->4) - чем больше времени тратится на оптимизацию при обучении, тем выше эта ошибка
        Общая ошибка - это сумма всех ошибок, описанных выше. Задача - снизить ее.
    5) Масштабы обучения:
        а) маленький (мало данных)- высока вероятность переобучения, из чего вытекает высокая estimation error. Допустимы
        традиционные методы оптимизации.
        б) большой (данных много, но мало времени) - много времени уходит на подбор параметров и оптимизацию, поэтому
        растет optimization error. Требуются нетрадиционные методы оптимизации.
    6) Оптмизация обучения:
        а) SGD
        Преимущества: используется обход мини-батчей (т.к. при реализации эти обходы могут выполняться параллельно),
        обход одного мини-батча называется эпохой, learning rate может быть константой или уменьшаться каждое число эпох,
        делясь на некоторое число (напрример, 10)
        Недостатки: обучение может быть скачкообразным
        б) улучшенный SGD - тоже самое, что в пункте а), только добавляется моментум (использование уже пройденного пути обучения,
        или, иначе говоря, суммы прошлых градиентов)
        Преимущества: моментум сохраняет данные, полученные на основе других мини-батчей; более гладкий спуск
        в) Nesterov momentum - как в пункте б), только вектор смещения определяется не из данной точки, а из
        той, в которой мы предположительно будем через итерацию
        г) Adagrad - в качестве learning rate выступает дробь, в знаменателе которой корень из суммы квадратов прошлых градиентов
        (+ эпсилон), а в числителе регулируемый параметр альфа. Смысл дроби: в знаменателе квадраты прошлых градиентов;
        если градиенты в некоторых точках имели большие вертикальные смещения, то тогда дальнейшие градиенты в этих точках
        будут делиться на квадраты этих смещений, делая горизонтальные смещения сильнее и устремляя движение ко дну.
        Недостаток - обучение быстро затухает
        д) RMSProp - как Adagrad, только берется среднее скользящее суммы квадратов градиентов
        е) Adadelta - как RMSProp, только вместо альфа некоторая функция.
        Преимущество: нет настраиваемых параметров (можно добавить к этой функции коэффициент)
        ж) Adam - как RMSProp, только вместо градиента используется его среднее скользящее, а также производится деление
        на параметры бета и мю, которые ускоряют обучение на первых итерациях, когда веса близки к нулю

        Топовый выбор - Adam или Nesterov momentum







